{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a58e3911",
      "metadata": {},
      "source": [
        "# Project: PDF Query System with Local Retrieval-Augmented Generation\n",
        "\n",
        "## Overview\n",
        "This project implements an **Improved Retrieval-Augmented Generation (RAG)** system that combines **information retrieval** with **language generation**.  \n",
        "It allows you to ask questions and get answers grounded in your own documents using **FAISS** for similarity search and **Transformer-based** models for text generation.\n",
        "\n",
        "The notebook is fully self-contained and modular, making it ideal for learning, experimentation, and extension into production-ready pipelines.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51c7a540",
      "metadata": {},
      "source": [
        "## 1) Requirements\n",
        "\n",
        "Install required libraries. Run these once in the notebook environment. If you have alternative libraries already installed, adapt accordingly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "295e564e",
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install -q -U sentence-transformers faiss-cpu transformers accelerate datasets tiktoken\n",
        "# Optional: if using OpenAI for generation\n",
        "# !pip install -q openai\n",
        "#!pip install PyPDF2 \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5d1c8ec",
      "metadata": {},
      "source": [
        "## 2) Imports and configuration\n",
        "\n",
        "Import libraries and set configuration variables. Use local models if you prefer. Keep keys secret; use environment variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "664f3271",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Config set. Data dir: Data\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple, Dict, Any\n",
        "\n",
        "# Config - replace or set as environment variables\n",
        "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')  # optional if you use OpenAI\n",
        "DATA_DIR = Path('Data')  # place your documents here\n",
        "EMBEDDING_MODEL = 'sentence-transformers/all-MiniLM-L6-v2'  # compact, fast\n",
        "GENERATION_MODEL = 'gpt2'  # placeholder. replace with a powerful local HF model or call OpenAI/GPT\n",
        "CHUNK_SIZE = 500\n",
        "CHUNK_OVERLAP = 50\n",
        "\n",
        "print('Config set. Data dir:', DATA_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81cdd73e",
      "metadata": {},
      "source": [
        "## 3) Load documents\n",
        "\n",
        "Load text files, PDFs, or other sources. This example reads `.txt` files. Split into chunks for better retrieval."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "32bdbd58",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 2 documents.\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "from typing import List, Tuple\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "def load_pdf_files(folder: Path) -> List[Tuple[str, str]]:\n",
        "    \"\"\"Return list of (source_name, text) from PDFs.\"\"\"\n",
        "    docs = []\n",
        "    if not folder.exists():\n",
        "        print('Data folder not found:', folder)\n",
        "        return docs\n",
        "    for p in folder.glob('**/*.pdf'):\n",
        "        try:\n",
        "            reader = PdfReader(p)\n",
        "            text = \"\\n\".join(page.extract_text() or \"\" for page in reader.pages)\n",
        "            docs.append((str(p), text))\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading {p}: {e}\")\n",
        "    return docs\n",
        "\n",
        "\n",
        "docs = load_pdf_files(DATA_DIR)\n",
        "print(f'Loaded {len(docs)} documents.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82b3d5c0",
      "metadata": {},
      "source": [
        "### 3.1) Text splitting\n",
        "\n",
        "Chunk long documents to maintain relevance and fit embedding model limits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "f0649f8d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Corpus chunks: 12\n"
          ]
        }
      ],
      "source": [
        "def chunk_text(text: str, size: int = CHUNK_SIZE, overlap: int = CHUNK_OVERLAP) -> List[str]:\n",
        "    tokens = text.split()\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    n = len(tokens)\n",
        "\n",
        "    while start < n:\n",
        "        end = min(start + size, n)\n",
        "        chunk = ' '.join(tokens[start:end])\n",
        "        chunks.append(chunk)\n",
        "        if end == n:\n",
        "            break\n",
        "        start += size - overlap  # move forward\n",
        "    return chunks\n",
        "# Build corpus: list of dicts with metadata\n",
        "corpus = []\n",
        "for src, text in docs:\n",
        "    z=chunk_text(text)\n",
        "    for i, chunk in enumerate(chunk_text(text)):\n",
        "        corpus.append({'source': src, 'chunk_id': i, 'text': chunk})\n",
        "print('Corpus chunks:', len(corpus))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "a3ab8a5a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a11894349d65471d94759c21ea673ac4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import login\n",
        "login()  # then paste your new HF token"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4453327",
      "metadata": {},
      "source": [
        "## 4) Create embeddings and FAISS index\n",
        "\n",
        "We create dense embeddings per chunk and add them to FAISS for nearest-neighbor retrieval."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "d025e4c1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8158418e431428f812b7f61485a8a7f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FAISS index built. vectors: 12 dim: 384\n",
            "Index and metadata saved: rag_index.faiss, rag_meta.pkl\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import faiss\n",
        "import pickle\n",
        "\n",
        "# Load embedding model\n",
        "embedder = SentenceTransformer(EMBEDDING_MODEL)\n",
        "\n",
        "def embed_texts(texts: List[str]) -> np.ndarray:\n",
        "    # Returns numpy array of shape (n, dim)\n",
        "    embs = embedder.encode(texts, show_progress_bar=True, convert_to_numpy=True)\n",
        "    return embs\n",
        "\n",
        "# Create texts list\n",
        "texts = [d['text'] for d in corpus]\n",
        "if len(texts) == 0:\n",
        "    print('No texts to embed. Add files to', DATA_DIR)\n",
        "else:\n",
        "    embeddings = embed_texts(texts)\n",
        "    dim = embeddings.shape[1]\n",
        "    # Build FAISS index (L2)\n",
        "    index = faiss.IndexFlatL2(dim)\n",
        "    index.add(embeddings)\n",
        "    print('FAISS index built. vectors:', index.ntotal, 'dim:', dim)\n",
        "\n",
        "    # Save metadata for retrieval\n",
        "    meta = corpus  # list of dicts aligned with embeddings rows\n",
        "\n",
        "    # Persist the index and meta\n",
        "    faiss.write_index(index, 'rag_index.faiss')\n",
        "    with open('rag_meta.pkl', 'wb') as f:\n",
        "        pickle.dump(meta, f)\n",
        "    print('Index and metadata saved: rag_index.faiss, rag_meta.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f17e14da",
      "metadata": {},
      "source": [
        "## 5) Retriever function\n",
        "\n",
        "Given a query, embed it and fetch top-k nearest chunks from FAISS. Return text and metadata."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "5481d2bb",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "668446aff3834015810e5c8a0e344b43",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieve test: [{'source': 'Data\\\\monopoly.pdf', 'chunk_id': 4, 'text': 'HOUSES: When you own all the propert~es in a color-group you may buy houses from the Bank and erect them on those properties. If you buy one house, you may put it on any one of those properties. The next house you buy must be erected on one of the unimproved properties of this or any other complete color- group you may own. The price you must pay the Bank for each house is shown on your ltle Deed card for the property on which you erect the house. The owner still collects double rent from an opponent who lands on the unimproved properties of hisher complete color-group. Following the above rules, you may buy and erect at any time as many houses as your judgement and financial standing will allow. But you must build evenly, i.e., you cannot erect more than one house on any one property of any color-group until you have built one house on wery property of that group. You may then begin on the second row of houses, and so on, up to a limit of four houses to a property. For example, you cannot build three houses on one property if you have only one house on another property of that group. As you build evenly, you must also break down evenly ifyou sell houses back to the Bank (see SELLING PROPERTY). HOTELS: When a player has four houses on each property of a complete color-group, hdshe may buy a hotel from the Bank and erect it on any property of the color-group. Hdshe returns the four houses from that property to the Bank and pays the price for the hotel as shown on the Ttle Deed card. Only one hotel may be erected on any one property. BUILDING SHORTAGES: When the Bank has no houses to sell, players wishing to build must wait for some player to return or sell histher houses to the Bank before building. If there are a limited number of houses and hotels available and two or more players wish to buy more than the Bank has, the houses or hotels must be sold at auction to the highest bidder. SELLING PROPERN: Unimproved properties, railroads and util~ties (but not buildings) may be sold to any player as a private transaction for any amount the owner can get; however, no property can be sold to - another player if buildings are standing on any properties of that color- group. Any buildings so located must be sold back to the Bank before the owner can sell any property of that color-group. Houses and hotels may be sold back to the Bank at any time for one- half the price paid for them. All houses on one color-group must be sold one by one, evenly, in reverse of the manner in which they were erected. All hotels on one color-group may be sold at once, or they may be sold one house at a time (one hotel equals five houses), evenly, in', 'score': 1.655970573425293}, {'source': 'Data\\\\ticket_to_ride.pdf', 'chunk_id': 2, 'text': 'are placed on the bottom of the deck. T rain Car Cards There are 8 types of regular Train Car cards, plus Locomotive cars. The colors of each type of Train Car card match various rou tes between cities on the board – Purple, Blue, Orange, White, Green, Yellow, Black, and Red. Locomotives are Multi-colored and act as a wild card that can be part of any set of cards when claiming a route. If a Locomotive card is one of the five face-up cards , the player who draws it may only draw one card, instead of two. If, after having drawn one card the replacement card is a Locomotive, the player cannot take it. If at any time, three of the five face-up cards are Locomotives, all five cards are immediately discarded and five new ones are turned face-up to replace them. Note: If a player is lucky enough to get a Locomotive from the top of the deck in a blind draw, it stills counts as a single card and he may still draw a total of two cards that turn. A player may have any number of cards in his hand at any time. When the deck is exhausted, the discards are reshuffled into a new draw pile deck. The cards should be shuffled thoroughly, since all the cards have been discarded in sets. In the unlikely event that there are no cards left in the deck and there are no discards (because players are hoarding many cards in their hands), a player cannot draw Train Car cards. Instead he may only claim a route or draw Destination Ticket cards. Claiming Routes To claim a route, a player must play a set of cards equal to the number of spaces in the route. A set of cards must be of the same type. Most routes require a specific type of set. For example a Blue route must be claimed using blue-colored Passenger Car cards. Some routes – those that are Gray colored – can be claimed using a set of cards of any one color. When a route is claimed, the player places one of his plastic trains in each of the spaces of the route. All the cards in the set used to claim the route are then discarded. A player may claim any open route on the board. He is never required to connect to any of his previously played routes. A player may only claima maximum of one route, hence connect two adjacent cities, never more,on his turn. Some cities are connected by Double-Routes . One player cannot claim both routes to the same cities. Important Note: In 2 or 3 player games, only one of the Double-Routes can be used. A player can claim either of the two routes between cities, but the other route is then closed to other players.∫ ∑ ∑∫ π ∏ ª To claim the route from Montréal to Toronto, a player could use any set of Train', 'score': 1.713585615158081}, {'source': 'Data\\\\monopoly.pdf', 'chunk_id': 5, 'text': 'them. All houses on one color-group must be sold one by one, evenly, in reverse of the manner in which they were erected. All hotels on one color-group may be sold at once, or they may be sold one house at a time (one hotel equals five houses), evenly, in reverse of the manner in which they were erected. MORTGAGES: Unimproved properties can be mortgaged through the Bank at any time. Before an improved property can be mortgaged, all the buildings on all the properties of its color-group must be sold back to the Bank at half price. The mortgage value is printed on each Title Deed card. No rent can be collected on mortgaged properties or utilities, but rent can be collected on unmortgaged properties in the same group. In order to lift the mortgage, the owner must pay the Bank the amount of the mortgage plus 10% interest. When all the propert~es of a color-group are no longer mortgaged, the owner may begin to buy back houses at full price. The player who mortgages property retains possession of it and no other player may secure it by lifting the mortgage from the Bank. However, the owner may sell this mortgaged property to another player at any agreed price. If you are the new owner, you may lift the mortgage at once if you wish by paying off the mortgage plus 10% interest to the Bank. If the mortgage is not lifted at once, you must pay the Bank 10% interest when you buy the property and if you lift the mortgage later you must pay the Bank an additional 10% interest as well as the amount of the mortgage. n BANKRUPTCY.. You are declared bankrupt if you owe more than you can pay either to another player or to the Bank. If your , debt is to another player, you must tum over to that player all that you have of value and retire from the game. In making this settlement, if you own houses or hotels, you must retum these to the Bank in exchange for money to the extent of one-half the amount paid for them; this cash is given to the creditor. If you have mortgaged property you also turn this property over to your creditor but the new owner must at once pay . the Bank the amount of interest on the loan, which is 10% of the value of the property. The new owner who does this may then, at hislher option, pay the principal or hold the property until some later turn, then lift the mortgage. If helshe holds property in this way until a later turn, helshe must pay the interest again upon lifting the mortgage. Should you owe the Bank, instead of another player, more than you can pay (because of taxes or penalties) even by selling off buildings and mortgaging property, you must turn over all assets to the Bank. In this case, the Bank immediately sells by auction', 'score': 1.7189316749572754}]\n"
          ]
        }
      ],
      "source": [
        "def load_index_and_meta(index_path='rag_index.faiss', meta_path='rag_meta.pkl'):\n",
        "    import pickle\n",
        "    import faiss\n",
        "    idx = faiss.read_index(index_path)\n",
        "    with open(meta_path, 'rb') as f:\n",
        "        meta = pickle.load(f)\n",
        "    return idx, meta\n",
        "\n",
        "index, meta = load_index_and_meta()\n",
        "\n",
        "def retrieve(query: str, top_k: int = 4) -> List[Dict[str, Any]]:\n",
        "    q_emb = embed_texts([query])\n",
        "    D, I = index.search(q_emb, top_k)\n",
        "    results = []\n",
        "    for dist, idx in zip(D[0], I[0]):\n",
        "        if idx < 0 or idx >= len(meta):\n",
        "            continue\n",
        "        entry = meta[idx].copy()\n",
        "        entry['score'] = float(dist)\n",
        "        results.append(entry)\n",
        "    return results\n",
        "\n",
        "# quick test (replace with your own query)\n",
        "print('Retrieve test:', retrieve('What is the architecture of the model?', top_k=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a768c558",
      "metadata": {},
      "source": [
        "## 6) Generator / RAG function\n",
        "\n",
        "Combine retrieved passages into a prompt and call a generator model. Two options shown: local HF model or OpenAI completion. Use whichever you have access to."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "c0173308",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "# Option A: local HuggingFace generation (no API key required)\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "\n",
        "# NOTE: gpt2 is small and not good for long-context RAG. Replace with a larger local model if available.\n",
        "tokenizer = AutoTokenizer.from_pretrained(GENERATION_MODEL)\n",
        "model = AutoModelForCausalLM.from_pretrained(GENERATION_MODEL, torch_dtype='auto', device_map='auto')\n",
        "generator = pipeline('text-generation', model=model, tokenizer=tokenizer, max_new_tokens=256)\n",
        "\n",
        "def generate_with_local(prompt: str) -> str:\n",
        "    out = generator(prompt, do_sample=False, num_return_sequences=1)\n",
        "    return out[0]['generated_text']\n",
        "\n",
        "# Option B: OpenAI (if you have an API key). Uncomment and set OPENAI_API_KEY above.\n",
        "# import openai\n",
        "# openai.api_key = OPENAI_API_KEY\n",
        "# def generate_with_openai(prompt: str, model='gpt-3.5-turbo'):\n",
        "#     resp = openai.ChatCompletion.create(\n",
        "#         model=model,\n",
        "#         messages=[{'role':'user','content':prompt}],\n",
        "#         temperature=0.0,\n",
        "#         max_tokens=256\n",
        "#     )\n",
        "#     return resp['choices'][0]['message']['content'].strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b937d3cc",
      "metadata": {},
      "source": [
        "### 6.1) RAG query helper\n",
        "\n",
        "Construct a compact prompt combining the user query and top retrieved passages. Then generate the answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "de9c3d24",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b2441174299419fbae75cbee34a38fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are a helpful assistant that answers questions based on the given context.\n",
            "Use only the information in the context to answer the question concisely. \n",
            "If the answer is not contained, say \"I don't know.\"\n",
            "\n",
            "Context:\n",
            "Source: Data\\ticket_to_ride.pdf\n",
            "Bonus card face up next to the board π. Shuffle the Destination Ticket cards and deal 3 cards to each player ∫. Each player looks at their Destination Tickets and decides which ones they wish to keep. A playermust keep at least two, but may keep all three if he chooses. Any returned cards areplaced on the bottom of the Destination Ticket deck. This deck is then placed next to theboard ª. Players keep their Destination Tickets secret until the end of the game. You are now ready to begin....\n",
            "---\n",
            "Source: Data\\ticket_to_ride.pdf\n",
            "only one of the Double-Routes can be used. A player can claim either of the two routes between cities, but the other route is then closed to other players.∫ ∑ ∑∫ π ∏ ª To claim the route from Montréal to Toronto, a player could use any set of Train Car cards, as a long as they are the same type.Example 2 To claim the route from Montréal to New York, a player would need a set of three Blue Passenger Car cards. Example 1[T2R] rules EN reprint 2015_TTR2 rules US 06/03/15 17:36 Page4 Route...\n",
            "---\n",
            "Source: Data\\ticket_to_ride.pdf\n",
            "include loops, and passthrough the same city several times, but a given plastic train may never be used twice in the same continuous path. In the case of a tie for the longestpath, all tied players score the 10 point bonus. The player with the most points wins the game. If two or more players are tied for the most points, the player who has completed the most Destination Tickets wins. In the unlikely event that they are still tied, the player with the Longest Continuous Path card wins. 1Route...\n",
            "\n",
            "Question:\n",
            "Explain the principles of the game Ticket to Ride.\n",
            "\n",
            "Answer:\n",
            "\n",
            "The game Ticket to Ride is a game of cards. Each player has a card that he or she chooses to play. The cards are shuffled to the bottom of the deck. The player who chooses to play the most cards wins. The player who chooses to play the least cards wins. The player who chooses to play the most cards wins. The player who chooses to play the least cards wins. The player who chooses to play the least cards wins. The player who chooses to play the least cards wins. The player who chooses to play the least cards wins. The player who chooses to play the least cards wins. The player who chooses to play the least cards wins. The player who chooses to play the least cards wins. The player who chooses to play the least cards wins. The player who chooses to play the least cards wins. The player who chooses to play the least cards wins. The player who chooses to play the least cards wins. The player who chooses to play the least cards wins. The player who chooses to play the least cards wins. The player who chooses to play the least cards wins. The player who chooses to play the least cards wins. The player who chooses to play the least cards wins. The player who chooses to play the least cards wins\n"
          ]
        }
      ],
      "source": [
        "from textwrap import shorten\n",
        "from typing import Dict, Any\n",
        "\n",
        "PROMPT_TEMPLATE = \"\"\"You are a helpful assistant that answers questions based on the given context.\n",
        "Use only the information in the context to answer the question concisely. \n",
        "If the answer is not contained, say \"I don't know.\"\n",
        "\n",
        "Context:\n",
        "{passages}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "def rag_answer(query: str, top_k: int = 4, use_openai: bool = False) -> Dict[str, Any]:\n",
        "    # Retrieve top-k relevant passages\n",
        "    hits = retrieve(query, top_k=top_k)\n",
        "\n",
        "    if not hits:\n",
        "        return {'answer': \"I don't know from the provided sources.\", 'retrieved': [], 'prompt': ''}\n",
        "\n",
        "    # Safely combine context passages\n",
        "    passages_list = []\n",
        "    for h in hits:\n",
        "        text = h['text'].replace('\\n', ' ')  # flatten newlines\n",
        "        # Only shorten if really long\n",
        "        if len(text) > 500:\n",
        "            text = shorten(text, width=500, placeholder='...')\n",
        "        passages_list.append(f\"Source: {h['source']}\\n{text}\")\n",
        "\n",
        "    passages = '\\n---\\n'.join(passages_list)\n",
        "\n",
        "    # Build prompt\n",
        "    prompt = PROMPT_TEMPLATE.format(passages=passages, question=query)\n",
        "\n",
        "    # Generate answer\n",
        "    if use_openai:\n",
        "        raise NotImplementedError('OpenAI generation not enabled in this environment.')\n",
        "    else:\n",
        "        ans = generate_with_local(prompt)\n",
        "\n",
        "    # Ensure the model doesn't just repeat the question\n",
        "    if ans.strip().lower() == query.strip().lower():\n",
        "        ans = \"I don't know from the provided sources.\"\n",
        "\n",
        "    return {'answer': ans, 'retrieved': hits, 'prompt': prompt}\n",
        "\n",
        "# Example usage\n",
        "res = rag_answer('Explain the principles of the game Ticket to Ride.', top_k=3)\n",
        "print(res['answer'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7682dbc",
      "metadata": {},
      "source": [
        "## Next steps checklist\n",
        "\n",
        "- [ ] Replace GENERATION_MODEL with a strong model or enable OpenAI.\n",
        "- [ ] Add PDF/Office parsing for richer ingestion.\n",
        "- [ ] Add caching for embeddings.\n",
        "- [ ] Add evaluation metrics and tests.\n",
        "\n",
        "File saved as `RAG_Improved.ipynb` in the notebook root."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
